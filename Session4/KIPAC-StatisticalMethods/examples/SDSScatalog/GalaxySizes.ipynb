{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrating Observed and Intrinsic Object Properties:\n",
    "# SDSS \"Galaxy\" Sizes\n",
    "\n",
    "\n",
    "* In a catalog, each galaxy's measurements come with \"error bars\" providing information about how *uncertain* we should be about each property of each galaxy.\n",
    "\n",
    "* This means that the distribution of \"observed\" galaxy properties (as reported in the catalog) is not the same as the underlying or \"intrinsic\" distribution.\n",
    "\n",
    "* Let's look at the distribution of *observed sizes* in the SDSS photometric object catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import SDSS\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "galaxies = \"SELECT top 1000 \\\n",
    "petroR50_i AS size, \\\n",
    "petroR50Err_i AS err \\\n",
    "FROM PhotoObjAll \\\n",
    "WHERE \\\n",
    "(type = '3' AND petroR50Err_i > 0)\"\n",
    "print (galaxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download data. This can take a few moments...\n",
    "data = SDSS.select(galaxies)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just in case, we saved a copy of the csv file you just downloaded, using:\n",
    "# !mkdir -p downloads\n",
    "# data = SDSS.select(galaxies, filename='downloads/SDSSgalaxysizes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Distribution of Observed SDSS \"Galaxy\" Sizes\n",
    "\n",
    "Let's look at a histogram of galaxy sizes, for 1000 objects classified as \"galaxies\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"downloads/SDSSgalaxysizes.csv\",usecols=[\"size\",\"err\"])\n",
    "\n",
    "data['size'].hist(bins=np.linspace(0.0,5.0,100),figsize=(12,7))\n",
    "matplotlib.pyplot.xlabel('Size / arcsec',fontsize=16)\n",
    "matplotlib.pyplot.title('SDSS Observed Size',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to notice:\n",
    "\n",
    "* No small objects (why not?)\n",
    "* A \"tail\" to large size\n",
    "* Some very large sizes that look a little odd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Are these large galaxies *actually* large, or have they just been measured that way?\n",
    "Let's look at the reported uncertainties on these sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', x='size', y='err',s=100,figsize=(12,7), alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Mock Data\n",
    "\n",
    "* Let's look at how distributions like this one can come about, by making a **generative model** for this dataset.\n",
    "\n",
    "\n",
    "* First, let's imagine a set of perfectly measured galaxies. They won't all have the same size, because the Universe isn't like that. Let's suppose the logarithm of their *intrinsic sizes* are drawn from a Gaussian distribution of width $S$ and mean $\\mu$. \n",
    "\n",
    "\n",
    "* To model one mock galaxy, we *draw a sample from this distribution*. To model the whole dataset, we draw 1000 samples.\n",
    "\n",
    "\n",
    "* Note that this is a similar activity to making random catalogs for use in correlation function summaries; here, though, we want to start comparing real data with mock data to begin *understanding* it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_galaxies(mu=np.log10(1.5),S=0.3,N=1000):\n",
    "    return pd.DataFrame({'size' : 10.0**(mu + S*np.random.randn(N))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mu = np.log10(1.5)\n",
    "S = 0.05\n",
    "intrinsic = generate_galaxies(mu=mu,S=S,N=1000)\n",
    "\n",
    "intrinsic.hist(bins=np.linspace(0.0,5.0,100),figsize=(12,7),color='green')\n",
    "matplotlib.pyplot.xlabel('Size / arcsec',fontsize=16)\n",
    "matplotlib.pyplot.title('Intrinsic Size',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some observational uncertainty. We can model this by drawing random Gaussian offsets $\\epsilon$ and add one to each intrinsic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_noise(sigma=0.3,N=1000):\n",
    "    return pd.DataFrame({'size' : sigma*np.random.randn(N)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma = 0.3\n",
    "errors = make_noise(sigma=sigma,N=1000)\n",
    "\n",
    "observed = intrinsic + errors\n",
    "\n",
    "observed.hist(bins=np.linspace(0.0,5.0,100),figsize=(12,7),color='red')\n",
    "matplotlib.pyplot.xlabel('Size / arcsec',fontsize=16)\n",
    "matplotlib.pyplot.title('Observed Size',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "both = pd.DataFrame({'SDSS': data['size'], 'Model': observed['size']}, columns=['SDSS', 'Model'])\n",
    "both.hist(alpha=0.5,bins=np.linspace(0.0,5.0,100),figsize=(12,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: How did we do? Is this a good model for our data?\n",
    "\n",
    "Play around with the _parameters_ $\\mu$, $S$ and $\\sigma$ and see if you can get a better match to the observed distribution of sizes.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing: let's look at the variances of these distributions.\n",
    "\n",
    "Recall: \n",
    "\n",
    "$V(x) = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\nu)^2$\n",
    "\n",
    "If $\\nu$, the population mean of $x$, is not known, an _estimator_ for $V$ is \n",
    "\n",
    "$\\hat{V}(x) = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2$\n",
    "\n",
    "where $\\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x_i$, the _sample mean_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V_data = np.var(data['size'])\n",
    "\n",
    "print (\"Variance of the SDSS distribution = \",np.round(V_data, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V_int   = np.var(intrinsic['size'])\n",
    "V_noise = np.var(errors['size'])\n",
    "V_obs   = np.var(observed['size'])\n",
    "\n",
    "print (\"Variance of the intrinsic distribution = \", np.round(V_int, 3))\n",
    "print (\"Variance of the noise = \", np.round(V_noise, 3))\n",
    "print (\"Variance of the observed distribution = \",  np.round(V_int + V_noise, 3), \\\n",
    "  \"cf\", np.round(V_obs, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may recall this last result from previous statistics courses.\n",
    "\n",
    "**Why is the variance of our mock dataset's galaxy sizes so much smaller than that of the SDSS sample?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Distributions\n",
    "\n",
    "In the above example we drew 1000 *samples* from two *probability distributions*:\n",
    "\n",
    "* The intrinsic size distribution, ${\\rm Pr}(R_{\\rm true}|\\mu,S)$\n",
    "\n",
    "\n",
    "* The \"error\" distribution, ${\\rm Pr}(R_{\\rm obs}|R_{\\rm true},\\sigma)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The procedure of drawing numbers from the first, and then adding numbers from the second, produced *mock data* - which then appeared to have been drawn from:\n",
    "\n",
    "* ${\\rm Pr}(R_{\\rm obs}|\\mu,S,\\sigma)$\n",
    "\n",
    "which is *broader* than either the intrinsic distribution or the error distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Q: What would we do differently if we wanted to simulate 1 Galaxy?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The three distributions are related by an integral:\n",
    "\n",
    "${\\rm Pr}(R_{\\rm obs}|\\mu,S,\\sigma) = \\int {\\rm Pr}(R_{\\rm obs}|R_{\\rm true},\\sigma) \\; {\\rm Pr}(R_{\\rm true}|\\mu,S) \\; dR_{\\rm true}$\n",
    "\n",
    "\n",
    "* Note that this is *not* a convolution, in general - but it's similar to one.\n",
    "\n",
    "\n",
    "* When we only plot the 1D histogram of *observed* sizes, we are *summing over* or \"marginalizing out\" the intrinsic ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Graphical Models\n",
    "\n",
    "We can draw a diagram representing the above combination of probability distributions, that:\n",
    "\n",
    "* Shows the dependencies between variables\n",
    "\n",
    "* Gives you a recipe for generating *mock data*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [We can do this in python, using the `daft` package.](FirstPGM.ipynb):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\"samplingdistributions.png\", width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting PGMs\n",
    "\n",
    "* Each \"node\" (circle or dot) in the graph above represents a *probability distribution* \n",
    "\n",
    "\n",
    "* Nodes marked with dots represent PDFs that are *delta functions* - that is, parameters that are asserted to have specific values (like we did with $\\mu$ for example: ${\\rm Pr}(\\mu) = \\delta(\\mu - \\log_{10}{1.5}$).\n",
    "\n",
    "\n",
    "* The \"edges\" in the graph show the conditional dependence of the parameters with each other: a node with an edge leading to it is a *conditional probability distribution*.\n",
    "\n",
    "\n",
    "* We do not need to specify the functional form for any of the other PDFs before writing down the PGM - it just illustrates the connections between parameters in our probabilistic model.\n",
    "\n",
    "\n",
    "* It's often helpful to write down the PGM *before* writing down the probability distributions, as we'll see later.\n",
    "\n",
    "\n",
    "* The integral over the intrinsic size is not implied by this graph: the PGM just shows how to generate observed sizes given other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Where should $\\sigma$ go?\n",
    "\n",
    "Talk to your neighbor about dependencies for a couple of minutes..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
